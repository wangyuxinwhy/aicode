{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyuxin/miniconda3/envs/aicode/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from aicode.aicode_reg_dataset import RegWithCodeDataset, RegWithCodeCollator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = RegWithCodeDataset('dataset/aicode_debug/', 10, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_with_code_collator = RegWithCodeCollator(tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=8, collate_fn=reg_with_code_collator.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] * * Импортируем необходимые для работы функции и классы * * [PAD] # This Python 3 environment comes with many helpful analytics libraries installed # It is defined by the kaggle / python Docker image : https : / / github. com / kaggle / docker - python # For example, here\\'s several helpful packages to load import numpy as np # linear algebra import pandas as pd # data processing, CSV file I / O ( e. g. pd. read _ csv ) # Input data files are available in the read - only \".. / input / \" directory # For example, running this ( by clicking run or pressing Shift + Enter ) will list all files under the input directory import os for dirname, _, filenames in os. walk (\\'/ kaggle / input\\') : for filename in filenames : print ( os. path. join ( dirname, filename ) ) # You can write up to 20GB to the current directory ( / kaggle / working / ) that gets preserved as output when you create a version using \" Save & Run All \" # You can also write temporary files to / kaggle / temp /, but they won\\'t be saved outside of the current session matplotlib. rcParams. update ( {\\'font. size\\': 14 } ) train _ df = pd. read _ csv ( TRAIN _ DATASET _ PATH ) train _ df. tail ( ) test _ df = pd. read _ csv ( TEST _ DATASET _ PATH ) test _ df. tail ( ) submission _ df = pd. read _ csv (\\'/ kaggle / input / real - estate - price [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(b['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_samples = samples\n",
    "markdowns = [reg_sample.markdown for reg_sample in reg_samples]\n",
    "markdown_tokens = tokenizer.encode(['a', 'b'], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[188, 1181, 22816, 1181, 22816, 1161], [173, 1116, 1181, 8057, 1116, 1181, 188, 1181, 8057, 1116, 1181, 2087, 188, 1810, 8057], [188, 1181, 8057, 1116, 1181, 173, 22816, 1181]]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_encode_plus(['sdfsdfsa', 'dsdfasd sdfasdf sdafa', 'sdfasd dfsd'], return_attention_mask=False, return_token_type_ids=False, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode([101,\n",
    " 188,\n",
    " 1181,\n",
    " 22816,\n",
    " 1181,\n",
    " 22816,\n",
    " 1161,\n",
    " 102,\n",
    " 173,\n",
    " 1116,\n",
    " 1181,\n",
    " 8057,\n",
    " 1116,\n",
    " 1181,\n",
    " 188,\n",
    " 1181,\n",
    " 8057,\n",
    " 1116,\n",
    " 1181,\n",
    " 2087,\n",
    " 188,\n",
    " 1810,\n",
    " 8057,\n",
    " 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[115,\n",
       " 115,\n",
       " 456,\n",
       " 28401,\n",
       " 28402,\n",
       " 16948,\n",
       " 20442,\n",
       " 28404,\n",
       " 17424,\n",
       " 20442,\n",
       " 28405,\n",
       " 19692,\n",
       " 28401,\n",
       " 488,\n",
       " 19692,\n",
       " 16948,\n",
       " 28393,\n",
       " 28407,\n",
       " 16948,\n",
       " 28396,\n",
       " 17424,\n",
       " 28401,\n",
       " 28413,\n",
       " 19692,\n",
       " 479,\n",
       " 28400,\n",
       " 14800,\n",
       " 491,\n",
       " 10286,\n",
       " 28393,\n",
       " 16948,\n",
       " 28404,\n",
       " 28413,\n",
       " 495,\n",
       " 28405,\n",
       " 17127,\n",
       " 28399,\n",
       " 28408,\n",
       " 17424,\n",
       " 17424,\n",
       " 483,\n",
       " 485,\n",
       " 28400,\n",
       " 10286,\n",
       " 28403,\n",
       " 28403,\n",
       " 28413,\n",
       " 115,\n",
       " 115]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(reg_samples[0].markdown, add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = load_from_disk('dataset/aicode/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '00001756c60be8',\n",
       " 'ancestor_id': '945aea18',\n",
       " 'parent_id': None,\n",
       " 'cells': [{'id': '1862f0a6',\n",
       "   'is_code': True,\n",
       "   'rank': 0,\n",
       "   'source': '# This Python 3 environment comes with many helpful analytics libraries installed\\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\\n# For example, here\\'s several helpful packages to load\\n\\nimport numpy as np # linear algebra\\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\\n\\n# Input data files are available in the read-only \"../input/\" directory\\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\\n\\nimport os\\nfor dirname, _, filenames in os.walk(\\'/kaggle/input\\'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \\n# You can also write temporary files to /kaggle/temp/, but they won\\'t be saved outside of the current session'},\n",
       "  {'id': '448eb224',\n",
       "   'is_code': False,\n",
       "   'rank': 1,\n",
       "   'source': '**Импортируем необходимые для работы функции и классы**'},\n",
       "  {'id': '2a9e43d6',\n",
       "   'is_code': True,\n",
       "   'rank': 2,\n",
       "   'source': 'import numpy as np\\nimport pandas as pd\\nimport random\\n\\nfrom sklearn.model_selection import train_test_split, cross_val_score\\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\\nfrom catboost import CatBoostRegressor\\nfrom sklearn.ensemble import RandomForestRegressor\\nfrom sklearn.metrics import r2_score as r2\\nfrom sklearn.model_selection import KFold, GridSearchCV\\n\\nfrom datetime import datetime\\n\\nimport matplotlib\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\n%matplotlib inline'},\n",
       "  {'id': '7e2f170a',\n",
       "   'is_code': False,\n",
       "   'rank': 3,\n",
       "   'source': '**Подключаем предупреждения**'},\n",
       "  {'id': '038b763d',\n",
       "   'is_code': True,\n",
       "   'rank': 4,\n",
       "   'source': \"import warnings\\nwarnings.filterwarnings('ignore')\"},\n",
       "  {'id': '77e56113',\n",
       "   'is_code': False,\n",
       "   'rank': 5,\n",
       "   'source': '**Устанавливаем значения, чтобы везде был одинаковый шрифт и размер**'},\n",
       "  {'id': '2eefe0ef',\n",
       "   'is_code': True,\n",
       "   'rank': 6,\n",
       "   'source': \"matplotlib.rcParams.update({'font.size': 14})\"},\n",
       "  {'id': '1ae087ab',\n",
       "   'is_code': False,\n",
       "   'rank': 7,\n",
       "   'source': '**Задаем функцию для подсчета метрик**'},\n",
       "  {'id': '0beab1cd',\n",
       "   'is_code': True,\n",
       "   'rank': 8,\n",
       "   'source': 'def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\\n    print(\"Train R2:\\\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\\n    print(\"Test R2:\\\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\\n    \\n    plt.figure(figsize=(18,10))\\n    \\n    plt.subplot(121)\\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\\n    plt.xlabel(\\'Predicted values\\')\\n    plt.ylabel(\\'True values\\')\\n    plt.title(\\'Train sample prediction\\')\\n    \\n    plt.subplot(122)\\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\\n    plt.xlabel(\\'Predicted values\\')\\n    plt.ylabel(\\'True values\\')\\n    plt.title(\\'Test sample prediction\\')\\n\\n    plt.show()'},\n",
       "  {'id': '8ffe0b25',\n",
       "   'is_code': False,\n",
       "   'rank': 9,\n",
       "   'source': '**Указываем путь к файлам с данными**'},\n",
       "  {'id': '9a78ab76',\n",
       "   'is_code': True,\n",
       "   'rank': 10,\n",
       "   'source': \"TRAIN_DATASET_PATH = '/kaggle/input/real-estate-price-prediction-moscow/train.csv'\\nTEST_DATASET_PATH = '/kaggle/input/real-estate-price-prediction-moscow/test.csv'\"},\n",
       "  {'id': '0d136e08',\n",
       "   'is_code': False,\n",
       "   'rank': 11,\n",
       "   'source': '**Загрузка данных**'},\n",
       "  {'id': '8a4c95d1',\n",
       "   'is_code': False,\n",
       "   'rank': 12,\n",
       "   'source': '*Описание датасета*\\n\\n**Id** - идентификационный номер квартиры\\n\\n**DistrictId** - идентификационный номер района\\n\\n**Rooms** - количество комнат\\n\\n**Square** - площадь\\n\\n**LifeSquare** - жилая площадь\\n\\n**KitchenSquare** - площадь кухни\\n\\n**Floor** - этаж\\n\\n**HouseFloor** - количество этажей в доме\\n\\n**HouseYear** - год постройки дома\\n\\n**Ecology_1, Ecology_2, Ecology_3** - экологические показатели местности\\n\\n**Social_1, Social_2, Social_3** - социальные показатели местности\\n\\n**Healthcare_1, Helthcare_2** - показатели местности, связанные с охраной здоровья\\n\\n**Shops_1, Shops_2** - показатели, связанные с наличием магазинов, торговых центров\\n\\n**Price** - цена квартиры'},\n",
       "  {'id': '23705731',\n",
       "   'is_code': False,\n",
       "   'rank': 13,\n",
       "   'source': '**Считываем обучающий набор данных**'},\n",
       "  {'id': 'ebe125d5',\n",
       "   'is_code': True,\n",
       "   'rank': 14,\n",
       "   'source': 'train_df = pd.read_csv(TRAIN_DATASET_PATH)\\ntrain_df.tail()'},\n",
       "  {'id': 'aaad8355',\n",
       "   'is_code': False,\n",
       "   'rank': 15,\n",
       "   'source': '*Тип данных обучающего сета*'},\n",
       "  {'id': 'd9dced8b', 'is_code': True, 'rank': 16, 'source': 'train_df.dtypes'},\n",
       "  {'id': '21616367',\n",
       "   'is_code': False,\n",
       "   'rank': 17,\n",
       "   'source': '*Деление признаков на числовые и текстовые*'},\n",
       "  {'id': '86497fe1',\n",
       "   'is_code': True,\n",
       "   'rank': 18,\n",
       "   'source': \"num_feat = list(train_df.select_dtypes(exclude='object').columns)\\nobj_feat = list(train_df.select_dtypes(include='object').columns)\\ntarget = 'Price'\\n\\nnum_feat\"},\n",
       "  {'id': 'c3ce0945',\n",
       "   'is_code': False,\n",
       "   'rank': 19,\n",
       "   'source': '**Считываем тестовый набор данных**'},\n",
       "  {'id': 'e2c8e725',\n",
       "   'is_code': True,\n",
       "   'rank': 20,\n",
       "   'source': 'test_df = pd.read_csv(TEST_DATASET_PATH)\\ntest_df.tail()'},\n",
       "  {'id': 'a6357f7e',\n",
       "   'is_code': False,\n",
       "   'rank': 21,\n",
       "   'source': '*Выводим сколько строк в тесте и на трейне*'},\n",
       "  {'id': 'ff7c44ed',\n",
       "   'is_code': True,\n",
       "   'rank': 22,\n",
       "   'source': \"print('Строк в трейне:', train_df.shape[0])\\nprint('Строк в тесте', test_df.shape[0])\"},\n",
       "  {'id': 'ac301a84',\n",
       "   'is_code': False,\n",
       "   'rank': 23,\n",
       "   'source': '*На обучении на один признак больше, чем на тесте*'},\n",
       "  {'id': '0e7c906e',\n",
       "   'is_code': True,\n",
       "   'rank': 24,\n",
       "   'source': 'train_df.shape[1] - 1 == test_df.shape[1]'},\n",
       "  {'id': 'dd0c804a',\n",
       "   'is_code': True,\n",
       "   'rank': 25,\n",
       "   'source': \"submission_df = pd.read_csv('/kaggle/input/real-estate-price-prediction-moscow/sample_submission.csv')\"},\n",
       "  {'id': '45082c89',\n",
       "   'is_code': False,\n",
       "   'rank': 26,\n",
       "   'source': '**Приведение типов**'},\n",
       "  {'id': '781bbf3c',\n",
       "   'is_code': True,\n",
       "   'rank': 27,\n",
       "   'source': \"train_df['Id'] = train_df['Id'].astype(str)\"},\n",
       "  {'id': '4bb2e30a',\n",
       "   'is_code': False,\n",
       "   'rank': 28,\n",
       "   'source': '**Поиск признаков с выбросами**'},\n",
       "  {'id': 'bd94f005',\n",
       "   'is_code': True,\n",
       "   'rank': 29,\n",
       "   'source': 'train_df[num_feat].hist(\\n    figsize=(16,16)\\n)\\nplt.show()'},\n",
       "  {'id': '63c26fa2',\n",
       "   'is_code': False,\n",
       "   'rank': 30,\n",
       "   'source': 'Выбросы наблюдаются в: HouseYear, KitchenSquare.\\n\\nПризнаки с аномально высоким значением, которые нужно будет ограничить: HouseFloor, LifeSquare, Rooms, Square.'},\n",
       "  {'id': '62638fba',\n",
       "   'is_code': True,\n",
       "   'rank': 31,\n",
       "   'source': 'train_df.describe().T'},\n",
       "  {'id': '3e5f860d',\n",
       "   'is_code': False,\n",
       "   'rank': 32,\n",
       "   'source': 'Признаки Rooms, KitchenSquare, HouseFloor имеют в некоторых наблюдениях нулевые значения'},\n",
       "  {'id': 'bb69e88c',\n",
       "   'is_code': True,\n",
       "   'rank': 33,\n",
       "   'source': \"grid = sns.jointplot(train_df['Rooms'], train_df['Price'], kind='reg')\\ngrid.fig.set_figwidth(8)\\ngrid.fig.set_figheight(8)\"},\n",
       "  {'id': '6b5664c7',\n",
       "   'is_code': True,\n",
       "   'rank': 34,\n",
       "   'source': \"grid = sns.jointplot(train_df['KitchenSquare'], train_df['Price'], kind='reg')\\ngrid.fig.set_figwidth(8)\\ngrid.fig.set_figheight(8)\"},\n",
       "  {'id': '3eebeb87',\n",
       "   'is_code': False,\n",
       "   'rank': 35,\n",
       "   'source': 'Значения меньше 1 и больше 250 отсекаем'},\n",
       "  {'id': '23783525',\n",
       "   'is_code': True,\n",
       "   'rank': 36,\n",
       "   'source': \"train_df_temp = train_df.loc[train_df['KitchenSquare']<250]\\ngrid = sns.jointplot(train_df_temp['KitchenSquare'], train_df_temp['Price'], kind='reg')\\ngrid.fig.set_figwidth(8)\\ngrid.fig.set_figheight(8)\"},\n",
       "  {'id': '36002912',\n",
       "   'is_code': False,\n",
       "   'rank': 37,\n",
       "   'source': 'За выброс посчитаем значения менее 3 кв.м. и больше 30 кв.м.'},\n",
       "  {'id': 'bfbde93e',\n",
       "   'is_code': False,\n",
       "   'rank': 38,\n",
       "   'source': '**График распределения целевой переменной - цены**'},\n",
       "  {'id': '8522781a',\n",
       "   'is_code': True,\n",
       "   'rank': 39,\n",
       "   'source': \"plt.figure(figsize = (16, 8))\\n\\ntrain_df['Price'].hist(bins=30)\\nplt.ylabel('Count')\\nplt.xlabel('Price')\\n\\nplt.title('Target distribution')\\nplt.show()\"},\n",
       "  {'id': '1496beaf', 'is_code': False, 'rank': 40, 'source': 'Корреляция'},\n",
       "  {'id': '8ca8392c',\n",
       "   'is_code': True,\n",
       "   'rank': 41,\n",
       "   'source': \"correlation = train_df.corrwith(train_df['Price']).sort_values(ascending=False)\\ncorrelation.drop('Price', inplace=True)\\n\\nplt.figure(figsize = (16, 8))\\nplt.bar(correlation.index, correlation)\\nplt.xticks(rotation='90')\\nplt.xlabel('Features', fontsize=15)\\nplt.ylabel('Correlation', fontsize=15)\\nplt.title('Feature correlation', fontsize=15)\\nplt.show()\"},\n",
       "  {'id': 'b69a4f9b',\n",
       "   'is_code': False,\n",
       "   'rank': 42,\n",
       "   'source': 'Создания класса подготовки данных'},\n",
       "  {'id': '17ec3fc4',\n",
       "   'is_code': True,\n",
       "   'rank': 43,\n",
       "   'source': 'class Data:\\n    \\n    def __init__(self):\\n        \"\"\"Константы для обработки выбросов на основе анализа данных\"\"\"\\n        self.Square_min = 15\\n        self.Square_max = 300\\n        \\n        self.LifeSquare_min = 10\\n        self.LifeSquare_max = 280\\n        \\n        self.Rooms_min = 1\\n        self.Rooms_max = 5\\n        \\n        self.HouseFloor_min = 1\\n        self.HouseFloor_max = 50\\n        \\n        self.KitchenSquare_min = 3\\n        self.KitchenSquare_max = 30\\n        \\n        self.current_year = datetime.now().year\\n        \\n        self.medians = None\\n        self.DistrictId_value_counts = None\\n        self.SquareMeterPrice_by_DistrictId = None\\n        self.Healthcare_1_by_DistrictId = None\\n        \\n        \\n    def fit(self, train_df):\\n        \\n        # медианные значения\\n        self.medians = train_df[[\\'LifeSquare\\', \\'HouseFloor\\']].median()\\n        \\n        # подсчет популярных районов\\n        self.DistrictId_value_counts = dict(train_df[\\'DistrictId\\'].value_counts())\\n        \\n        # подсчет средней цены за м2 по району\\n        train_df_temp = train_df.loc[((train_df[\\'Square\\'] > self.Square_min) & (train_df[\\'Square\\'] < self.Square_max))]\\n        train_df_temp[\"SquareMeterPrice\"] = train_df_temp[\"Price\"] / train_df_temp[\"Square\"]\\n        self.SquareMeterPrice_by_DistrictId = train_df_temp.groupby(\\'DistrictId\\', as_index=False)\\\\\\n            .agg({\\'SquareMeterPrice\\': \\'mean\\'})\\\\\\n            .rename(columns={\\'SquareMeterPrice\\': \\'AverageSquareMeterPrice\\'})\\n        \\n        # подсчет среднего значения признака Healthcare_1 по району\\n        self.Healthcare_1_by_DistrictId = train_df.groupby(\\'DistrictId\\', as_index=False)\\\\\\n            .agg({\\'Healthcare_1\\': \\'mean\\'})\\\\\\n            .rename(columns={\\'Healthcare_1\\': \\'AverageHealthcare_1\\'})\\n        \\n        del train_df_temp\\n        \\n    def transform(self, train_df):\\n        \\n        # Обработка пропусков\\n        train_df[[\\'LifeSquare\\', \\'HouseFloor\\']] = train_df[[\\'LifeSquare\\', \\'HouseFloor\\']].fillna(self.medians)\\n        \\n        # Обработка выбросов\\n        \\n        # площадь\\n        train_df.loc[(train_df[\\'Square\\'] > self.Square_max), \\'Square\\'] = self.Square_max\\n        train_df.loc[(train_df[\\'Square\\'] < self.Square_min), \\'Square\\'] = self.Square_min\\n        \\n        # жилая площадь\\n        train_df.loc[(train_df[\\'LifeSquare\\'] < self.LifeSquare_min), \\'LifeSquare\\'] = self.LifeSquare_min\\n        train_df.loc[(train_df[\\'LifeSquare\\'] > self.LifeSquare_max), \\'LifeSquare\\'] = self.LifeSquare_max\\n        \\n        # площадь кухни\\n        train_df.loc[(train_df[\\'KitchenSquare\\'] < self.KitchenSquare_min), \\'KitchenSquare\\'] = self.KitchenSquare_min\\n        train_df.loc[(train_df[\\'KitchenSquare\\'] > self.KitchenSquare_max), \\'KitchenSquare\\'] = self.KitchenSquare_max\\n        \\n        # год постройки дома\\n        train_df.loc[(train_df[\\'HouseYear\\'] > self.current_year), \\'HouseYear\\'] = self.current_year\\n        \\n        # количество комнат\\n        train_df.loc[(train_df[\\'Rooms\\'] > self.Rooms_max), \\'Rooms\\'] = self.Rooms_max\\n        train_df.loc[(train_df[\\'Rooms\\'] < self.Rooms_min), \\'Rooms\\'] = self.Rooms_min\\n        \\n        # количество этажей\\n        train_df.loc[(train_df[\\'HouseFloor\\'] < self.HouseFloor_min), \\'HouseFloor\\'] = self.HouseFloor_min\\n        train_df.loc[(train_df[\\'HouseFloor\\'] > self.HouseFloor_max), \\'HouseFloor\\'] = self.HouseFloor_max\\n        \\n        # если этаж больше этажности дома, то присваиваем случайный этаж от self.HouseFloor_min до максимального этажа в доме\\n        floor_outliers = train_df.loc[train_df[\\'Floor\\'] > train_df[\\'HouseFloor\\']].index\\n        train_df.loc[floor_outliers, \\'Floor\\'] = train_df.loc[floor_outliers, \\'HouseFloor\\'].apply(lambda x: self.HouseFloor_min if (self.HouseFloor_min == x) else np.random.randint(self.HouseFloor_min, x))\\n        \\n        # Обработка категорий\\n        train_df = pd.concat([train_df, pd.get_dummies(train_df[\\'Ecology_2\\'], prefix=\\'Ecology_2\\', dtype=\\'int8\\')], axis=1)\\n        train_df = pd.concat([train_df, pd.get_dummies(train_df[\\'Ecology_3\\'], prefix=\\'Ecology_3\\', dtype=\\'int8\\')], axis=1)\\n        train_df = pd.concat([train_df, pd.get_dummies(train_df[\\'Shops_2\\'], prefix=\\'Shops_2\\', dtype=\\'int8\\')], axis=1)\\n        \\n        return train_df\\n    \\n    def features(self, train_df):\\n        \\n        # добавление признака популярности района\\n        train_df[\\'DistrictId_counts\\'] = train_df[\\'DistrictId\\'].map(self.DistrictId_value_counts)\\n        train_df[\\'DistrictId_counts\\'].fillna(train_df[\\'DistrictId_counts\\'].median(), inplace=True)\\n        \\n        # добавление признака средней стоимости м2 по району\\n        train_df = train_df.merge(self.SquareMeterPrice_by_DistrictId, on=[\"DistrictId\"], how=\\'left\\')\\n        train_df[\\'AverageSquareMeterPrice\\'].fillna(train_df[\\'AverageSquareMeterPrice\\'].median(), inplace=True)\\n        \\n        # добавление признака среднего значения Healthcare_1 по району\\n        train_df = train_df.merge(self.Healthcare_1_by_DistrictId, on=[\"DistrictId\"], how=\\'left\\')\\n        train_df[\\'AverageHealthcare_1\\'].fillna(train_df[\\'AverageHealthcare_1\\'].median(), inplace=True)\\n        \\n        return train_df'},\n",
       "  {'id': '503926eb',\n",
       "   'is_code': False,\n",
       "   'rank': 44,\n",
       "   'source': 'Инициализация класса Data'},\n",
       "  {'id': '76512d50',\n",
       "   'is_code': True,\n",
       "   'rank': 45,\n",
       "   'source': 'data_inst = Data()\\n\\n# тренировочные данные\\ndata_inst.fit(train_df)\\ntrain_df = data_inst.transform(train_df)\\ntrain_df = data_inst.features(train_df)\\n\\n# валидационные данные\\ntest_df = data_inst.transform(test_df)\\ntest_df = data_inst.features(test_df)'},\n",
       "  {'id': '032e2820',\n",
       "   'is_code': False,\n",
       "   'rank': 46,\n",
       "   'source': 'Создаем список признаков, используемых в модели - отбор признаков'},\n",
       "  {'id': 'a98c5d9f',\n",
       "   'is_code': True,\n",
       "   'rank': 47,\n",
       "   'source': \"feature_names = ['AverageSquareMeterPrice', 'DistrictId_counts', 'Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor',\\n                    'HouseFloor', 'HouseYear', 'Helthcare_2', 'Ecology_1', 'Social_1', 'Social_2', 'Social_3',\\n                    'Shops_1', 'Ecology_2_A', 'Ecology_2_B', 'Ecology_3_A', 'Ecology_3_B', 'Shops_2_A', 'Shops_2_B',\\n                    'AverageHealthcare_1']\\ntarget_name = 'Price'\"},\n",
       "  {'id': '06365725',\n",
       "   'is_code': True,\n",
       "   'rank': 48,\n",
       "   'source': \"train_df = train_df[feature_names + [target_name]]\\ntest_df = test_df[feature_names + ['Id']]\\nX = train_df[feature_names]\\ny = train_df[target_name]\"},\n",
       "  {'id': '8554b284',\n",
       "   'is_code': False,\n",
       "   'rank': 49,\n",
       "   'source': '**Обучение модели на CatBoostRegressor**\\n\\nВычисления гиперпараметров модели при помощи randomized_search() learning_rate=0.1 iterations=1150 depth=8'},\n",
       "  {'id': '59959af5',\n",
       "   'is_code': True,\n",
       "   'rank': 50,\n",
       "   'source': \"final_model = CatBoostRegressor(\\n    silent=True,\\n    learning_rate=0.1,\\n    iterations=1150,\\n    eval_metric='R2',\\n    depth=8\\n)\\n\\nfinal_model.fit(X, y)\\n\\ncv_score = cross_val_score(\\n    final_model,\\n    X,\\n    y,\\n    scoring='r2',\\n    cv=KFold(\\n            n_splits=5,\\n            shuffle=True,\\n            random_state=42\\n    )\\n)\"},\n",
       "  {'id': '2e1a5949', 'is_code': False, 'rank': 51, 'source': 'Оценка модели'},\n",
       "  {'id': '80151ab7',\n",
       "   'is_code': True,\n",
       "   'rank': 52,\n",
       "   'source': \"print(f'R2: {round(cv_score.mean(), 3)}')\"},\n",
       "  {'id': 'fcb6792d',\n",
       "   'is_code': False,\n",
       "   'rank': 53,\n",
       "   'source': '**Сортировка признаков по важности**'},\n",
       "  {'id': '5bf9ca51',\n",
       "   'is_code': True,\n",
       "   'rank': 54,\n",
       "   'source': \"feature_importances = pd.DataFrame(\\n    zip(X.columns, final_model.get_feature_importance()),\\n    columns=['feature_name', 'importance']\\n)\\n\\nfeature_importances.sort_values(by='importance', ascending=False, inplace=True)\\nfeature_importances.head(20)\"},\n",
       "  {'id': '915643b3',\n",
       "   'is_code': False,\n",
       "   'rank': 55,\n",
       "   'source': '**Создание датафрейма с предсказаниями**'},\n",
       "  {'id': 'f5504853',\n",
       "   'is_code': True,\n",
       "   'rank': 56,\n",
       "   'source': \"preds_final = pd.DataFrame()\\npreds_final['Id'] = test_df['Id'].copy()\\n\\ntest_df.set_index('Id', inplace=True)\\ntest_df = test_df[feature_names]\"},\n",
       "  {'id': '9f50dca0',\n",
       "   'is_code': True,\n",
       "   'rank': 57,\n",
       "   'source': \"y_pred_final = final_model.predict(test_df)\\n\\nsubmission_df['Price'] = y_pred_final\\nsubmission_df.to_csv('./predictions.csv', index=False, encoding='utf-8', sep=',')\\n\\nsubmission_df.head()\"}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# This Python 3 environment comes with many helpful analytics libraries installed\n",
      "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
      "# For example, here's several helpful packages to load\n",
      "\n",
      "import numpy as np # linear algebra\n",
      "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
      "\n",
      "# Input data files are available in the read-only \"../input/\" directory\n",
      "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
      "\n",
      "import os\n",
      "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
      "    for filename in filenames:\n",
      "        print(os.path.join(dirname, filename))\n",
      "\n",
      "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
      "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
      "matplotlib.rcParams.update({'font.size': 14})\n",
      "train_df = pd.read_csv(TRAIN_DATASET_PATH)\n",
      "train_df.tail()\n",
      "test_df = pd.read_csv(TEST_DATASET_PATH)\n",
      "test_df.tail()\n",
      "submission_df = pd.read_csv('/kaggle/input/real-estate-price-prediction-moscow/sample_submission.csv')\n",
      "train_df.describe().T\n",
      "train_df_temp = train_df.loc[train_df['KitchenSquare']<250]\n",
      "grid = sns.jointplot(train_df_temp['KitchenSquare'], train_df_temp['Price'], kind='reg')\n",
      "grid.fig.set_figwidth(8)\n",
      "grid.fig.set_figheight(8)\n",
      "class Data:\n",
      "    \n",
      "    def __init__(self):\n",
      "        \"\"\"Константы для обработки выбросов на основе анализа данных\"\"\"\n",
      "        self.Square_min = 15\n",
      "        self.Square_max = 300\n",
      "        \n",
      "        self.LifeSquare_min = 10\n",
      "        self.LifeSquare_max = 280\n",
      "        \n",
      "        self.Rooms_min = 1\n",
      "        self.Rooms_max = 5\n",
      "        \n",
      "        self.HouseFloor_min = 1\n",
      "        self.HouseFloor_max = 50\n",
      "        \n",
      "        self.KitchenSquare_min = 3\n",
      "        self.KitchenSquare_max = 30\n",
      "        \n",
      "        self.current_year = datetime.now().year\n",
      "        \n",
      "        self.medians = None\n",
      "        self.DistrictId_value_counts = None\n",
      "        self.SquareMeterPrice_by_DistrictId = None\n",
      "        self.Healthcare_1_by_DistrictId = None\n",
      "        \n",
      "        \n",
      "    def fit(self, train_df):\n",
      "        \n",
      "        # медианные значения\n",
      "        self.medians = train_df[['LifeSquare', 'HouseFloor']].median()\n",
      "        \n",
      "        # подсчет популярных районов\n",
      "        self.DistrictId_value_counts = dict(train_df['DistrictId'].value_counts())\n",
      "        \n",
      "        # подсчет средней цены за м2 по району\n",
      "        train_df_temp = train_df.loc[((train_df['Square'] > self.Square_min) & (train_df['Square'] < self.Square_max))]\n",
      "        train_df_temp[\"SquareMeterPrice\"] = train_df_temp[\"Price\"] / train_df_temp[\"Square\"]\n",
      "        self.SquareMeterPrice_by_DistrictId = train_df_temp.groupby('DistrictId', as_index=False)\\\n",
      "            .agg({'SquareMeterPrice': 'mean'})\\\n",
      "            .rename(columns={'SquareMeterPrice': 'AverageSquareMeterPrice'})\n",
      "        \n",
      "        # подсчет среднего значения признака Healthcare_1 по району\n",
      "        self.Healthcare_1_by_DistrictId = train_df.groupby('DistrictId', as_index=False)\\\n",
      "            .agg({'Healthcare_1': 'mean'})\\\n",
      "            .rename(columns={'Healthcare_1': 'AverageHealthcare_1'})\n",
      "        \n",
      "        del train_df_temp\n",
      "        \n",
      "    def transform(self, train_df):\n",
      "        \n",
      "        # Обработка пропусков\n",
      "        train_df[['LifeSquare', 'HouseFloor']] = train_df[['LifeSquare', 'HouseFloor']].fillna(self.medians)\n",
      "        \n",
      "        # Обработка выбросов\n",
      "        \n",
      "        # площадь\n",
      "        train_df.loc[(train_df['Square'] > self.Square_max), 'Square'] = self.Square_max\n",
      "        train_df.loc[(train_df['Square'] < self.Square_min), 'Square'] = self.Square_min\n",
      "        \n",
      "        # жилая площадь\n",
      "        train_df.loc[(train_df['LifeSquare'] < self.LifeSquare_min), 'LifeSquare'] = self.LifeSquare_min\n",
      "        train_df.loc[(train_df['LifeSquare'] > self.LifeSquare_max), 'LifeSquare'] = self.LifeSquare_max\n",
      "        \n",
      "        # площадь кухни\n",
      "        train_df.loc[(train_df['KitchenSquare'] < self.KitchenSquare_min), 'KitchenSquare'] = self.KitchenSquare_min\n",
      "        train_df.loc[(train_df['KitchenSquare'] > self.KitchenSquare_max), 'KitchenSquare'] = self.KitchenSquare_max\n",
      "        \n",
      "        # год постройки дома\n",
      "        train_df.loc[(train_df['HouseYear'] > self.current_year), 'HouseYear'] = self.current_year\n",
      "        \n",
      "        # количество комнат\n",
      "        train_df.loc[(train_df['Rooms'] > self.Rooms_max), 'Rooms'] = self.Rooms_max\n",
      "        train_df.loc[(train_df['Rooms'] < self.Rooms_min), 'Rooms'] = self.Rooms_min\n",
      "        \n",
      "        # количество этажей\n",
      "        train_df.loc[(train_df['HouseFloor'] < self.HouseFloor_min), 'HouseFloor'] = self.HouseFloor_min\n",
      "        train_df.loc[(train_df['HouseFloor'] > self.HouseFloor_max), 'HouseFloor'] = self.HouseFloor_max\n",
      "        \n",
      "        # если этаж больше этажности дома, то присваиваем случайный этаж от self.HouseFloor_min до максимального этажа в доме\n",
      "        floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\n",
      "        train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor'].apply(lambda x: self.HouseFloor_min if (self.HouseFloor_min == x) else np.random.randint(self.HouseFloor_min, x))\n",
      "        \n",
      "        # Обработка категорий\n",
      "        train_df = pd.concat([train_df, pd.get_dummies(train_df['Ecology_2'], prefix='Ecology_2', dtype='int8')], axis=1)\n",
      "        train_df = pd.concat([train_df, pd.get_dummies(train_df['Ecology_3'], prefix='Ecology_3', dtype='int8')], axis=1)\n",
      "        train_df = pd.concat([train_df, pd.get_dummies(train_df['Shops_2'], prefix='Shops_2', dtype='int8')], axis=1)\n",
      "        \n",
      "        return train_df\n",
      "    \n",
      "    def features(self, train_df):\n",
      "        \n",
      "        # добавление признака популярности района\n",
      "        train_df['DistrictId_counts'] = train_df['DistrictId'].map(self.DistrictId_value_counts)\n",
      "        train_df['DistrictId_counts'].fillna(train_df['DistrictId_counts'].median(), inplace=True)\n",
      "        \n",
      "        # добавление признака средней стоимости м2 по району\n",
      "        train_df = train_df.merge(self.SquareMeterPrice_by_DistrictId, on=[\"DistrictId\"], how='left')\n",
      "        train_df['AverageSquareMeterPrice'].fillna(train_df['AverageSquareMeterPrice'].median(), inplace=True)\n",
      "        \n",
      "        # добавление признака среднего значения Healthcare_1 по району\n",
      "        train_df = train_df.merge(self.Healthcare_1_by_DistrictId, on=[\"DistrictId\"], how='left')\n",
      "        train_df['AverageHealthcare_1'].fillna(train_df['AverageHealthcare_1'].median(), inplace=True)\n",
      "        \n",
      "        return train_df\n",
      "train_df = train_df[feature_names + [target_name]]\n",
      "test_df = test_df[feature_names + ['Id']]\n",
      "X = train_df[feature_names]\n",
      "y = train_df[target_name]\n",
      "y_pred_final = final_model.predict(test_df)\n",
      "\n",
      "submission_df['Price'] = y_pred_final\n",
      "submission_df.to_csv('./predictions.csv', index=False, encoding='utf-8', sep=',')\n",
      "\n",
      "submission_df.head()\n"
     ]
    }
   ],
   "source": [
    "for code in dataset.reg_samples[0].codes:\n",
    "    print(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aicode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3d3bcb45d6b1f383c94d902571908b4b5c05232f778950c2106159cfd3f2966"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
